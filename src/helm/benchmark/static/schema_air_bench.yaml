---
############################################################
metrics:
  # Infrastructure metrics:
  - name: num_perplexity_tokens
    display_name: '# tokens'
    description: Average number of tokens in the predicted output (for language modeling, the input too).
  - name: num_bytes
    display_name: '# bytes'
    description: Average number of bytes in the predicted output (for language modeling, the input too).

  - name: num_references
    display_name: '# ref'
    description: Number of references.
  - name: num_train_trials
    display_name: '# trials'
    description: Number of trials, where in each trial we choose an independent, random set of training instances.
  - name: estimated_num_tokens_cost
    display_name: 'cost'
    description: An estimate of the number of tokens (including prompt and output completions) needed to perform the request.
  - name: num_prompt_tokens
    display_name: '# prompt tokens'
    description: Number of tokens in the prompt.
  - name: num_prompt_characters
    display_name: '# prompt chars'
    description: Number of characters in the prompt.
  - name: num_completion_tokens
    display_name: '# completion tokens'
    description: Actual number of completion tokens (over all completions).
  - name: num_output_tokens
    display_name: '# output tokens'
    description: Actual number of output tokens.
  - name: max_num_output_tokens
    display_name: 'Max output tokens'
    description: Maximum number of output tokens (overestimate since we might stop earlier due to stop sequences).
  - name: num_requests
    display_name: '# requests'
    description: Number of distinct API requests.
  - name: num_instances
    display_name: '# eval'
    description: Number of evaluation instances.
  - name: num_train_instances
    display_name: '# train'
    description: Number of training instances (e.g., in-context examples).
  - name: prompt_truncated
    display_name: truncated
    description: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).
  - name: finish_reason_length
    display_name: finish b/c length
    description: Fraction of instances where the the output was terminated because of the max tokens limit.
  - name: finish_reason_stop
    display_name: finish b/c stop
    description: Fraction of instances where the the output was terminated because of the stop sequences.
  - name: finish_reason_endoftext
    display_name: finish b/c endoftext
    description: Fraction of instances where the the output was terminated because the end of text token was generated.
  - name: finish_reason_unknown
    display_name: finish b/c unknown
    description: Fraction of instances where the the output was terminated for unknown reasons.
  - name: num_completions
    display_name: '# completions'
    description: Number of completions.
  - name: predicted_index
    display_name: Predicted index
    description: Integer index of the reference (0, 1, ...) that was predicted by the model (for multiple-choice).

  # Efficiency metrics:
  - name: inference_runtime
    display_name: Observed inference runtime (s)
    short_display_name: Observed inference time (s)
    lower_is_better: true
    description: Average observed time to process a request to the model (via an API, and thus depends on particular deployment).

  # AIRBench 2024 Top Level Score
  - name: air_score
    display_name: AIR Score
    short_display_name: AIR Score
    description: AIR Score
    lower_is_better: true

  # AIRBench 2024 Level 1 Category Scores
  - name: air_category_2_score
    display_name: AIR Category 2 Score
    short_display_name: AIR Category 2 Score
    description: AIR Category 2 Score
    lower_is_better: true

  - name: air_category_15_score
    display_name: AIR Category 2 Score
    short_display_name: AIR Category 2 Score
    description: AIR Category 2 Score
    lower_is_better: true

  # AIRBench 2024 Level 2 Category Scores
  - name: air_category_15_4142_score
    display_name: AIR Category 15.4142 Score
    short_display_name: AIR Category 15.4142 Score
    description: AIR Category 15.4142 Score
    lower_is_better: true

  - name: air_category_2_5_score
    display_name: AIR Category 2.5 Score
    short_display_name: AIR Category 2.5 Score
    description: AIR Category 2.5 Score
    lower_is_better: true

  # AIRBench 2024 Level 4 Category Scores
  - name: air_category_2_6_22_score
    display_name: AIR Category 2.6.22 Score
    short_display_name: AIR Category 2.6.22 Score
    description: AIR Category 2.6.22 Score
    lower_is_better: true

  - name: air_category_11_35_1_score
    display_name: AIR Category 11.35.1 Score
    short_display_name: AIR Category 11.35.1 Score
    description: AIR Category 11.35.1 Score
    lower_is_better: true

############################################################
perturbations: []

############################################################
metric_groups:
  - name: air_top_level_scores
    display_name: AIR Top Level
    hide_win_rates: true
    metrics:
      - name: air_score
        split: ${main_split}

  - name: air_level_2_scores
    display_name: AIR Level 2
    hide_win_rates: true
    metrics:
      - name: air_category_2_score
        split: ${main_split}
      - name: air_category_15_score
        split: ${main_split}

  - name: air_level_3_scores
    display_name: AIR Level 3
    hide_win_rates: true
    metrics:
      - name: air_category_2_5_score
        split: ${main_split}
      - name: air_category_15_4142_score
        split: ${main_split}

  - name: air_level_4_scores
    display_name: AIR Level 4
    hide_win_rates: true
    metrics:
      - name: air_category_2_6_22_score
        split: ${main_split}
      - name: air_category_11_35_1_score
        split: ${main_split}

  - name: efficiency
    display_name: Efficiency
    hide_win_rates: true
    metrics:
    - name: inference_runtime
      split: ${main_split}

  - name: general_information
    display_name: General information
    hide_win_rates: true
    metrics:
    - name: num_instances
      split: ${main_split}
    - name: num_train_instances
      split: ${main_split}
    - name: prompt_truncated
      split: ${main_split}
    - name: num_prompt_tokens
      split: ${main_split}
    - name: num_output_tokens
      split: ${main_split}

############################################################

run_groups:
  - name: safety_scenarios
    display_name: Safety Scenarios
    description: Safety Scenarios
    category: All Scenarios
    subgroups:
      - air_bench_2024

  - name: air_bench_2024
    display_name: AIRBench 2024
    description: >
      AIRBench 2024 is a AI safety benchmark that aligns with emerging government
      regulations and company policies. It consists of diverse, malicious prompts
      spanning categories of the regulation-based safety categories in the
      AIR 2024 safety taxonomy.
    metric_groups:
      - air_top_level_scores
      - air_level_2_scores
      - air_level_3_scores
      - air_level_4_scores
      - efficiency
      - general_information
    environment:
      main_name: air_score
      main_split: test
    taxonomy:
      task: open-ended instruction-following text generation
      what: malicious prompts
      who: dataset authors and language models
      when: "2024"
      language: English
